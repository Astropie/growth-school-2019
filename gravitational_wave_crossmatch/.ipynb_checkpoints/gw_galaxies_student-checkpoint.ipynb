{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gravitational Wave Localizations and Galaxy Crossmatch Module\n",
    "\n",
    "**Lecturer:** Leo Singer<br>\n",
    "**Jupyter Notebook Authors:** Leo Singer, Dave Cook, & Cameron Hummels\n",
    "\n",
    "This is a Jupyter notebook lesson taken from the GROWTH Summer School 2019.  For other lessons and their accompanying lectures, please see: http://growth.caltech.edu/growth-school-2019.html\n",
    "## Objective\n",
    "Learn how to use LIGO/Virgo localizations and match with galaxies\n",
    "\n",
    "## Key steps\n",
    "- Manipulate HEALPix localization files\n",
    "- Cross-match a LIGO localization with a galaxy catalog\n",
    "\n",
    "## Required dependencies\n",
    "\n",
    "See GROWTH school webpage for detailed instructions on how to install these modules and packages.  Nominally, you should be able to install the python modules with `pip install <module>`.  The external astromatic packages are easiest installed using package managers (e.g., `rpm`, `apt-get`).\n",
    "\n",
    "### Python modules\n",
    "* python 3\n",
    "* astropy\n",
    "* numpy\n",
    "* scipy\n",
    "* matplotlib\n",
    "* healpy\n",
    "* ligo.skymap\n",
    "\n",
    "### External packages\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some imports: Numpy, Matplotlib, Healpy, and parts of Astropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.utils.data\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import healpy as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some extra imports for the galaxy cross matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table, vstack, hstack, Column\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "import ligo.skymap.plot\n",
    "from scipy.stats import norm\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And configure Matplotlib to send plot output directly to the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HEALPix Basics\n",
    "\n",
    "This section on using HEALPix localization files is adapted from the [LIGO/Virgo Public Alerts User Guide](https://emfollow.docs.ligo.org/userguide/tutorial/skymaps.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and read localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by downloading a sample localization file from the User Guide. We could do this on the command line using `curl`:\n",
    "\n",
    "    $ curl -O https://emfollow.docs.ligo.org/userguide/_static/bayestar.fits.gz\n",
    "\n",
    "But after all, this is a Python lesson, so let's download the file using the handy `astropy.utils.data.download_file` function from Astropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://emfollow.docs.ligo.org/userguide/_static/bayestar.fits.gz'\n",
    "filename = astropy.utils.data.download_file(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's read in the HEALPix data using Healpy. Note that by default, Healpy only reads the first column, which provides the 2D probability distribution on the sky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSIDE = 2048\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n"
     ]
    }
   ],
   "source": [
    "prob = hp.read_map(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating HEALPix Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a quick look at a HEALPix data set, you can use the `hp.mollview` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What actually is stored in `prob`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a one-dimensional array! Yet it represents in 2D image. How does that work? HEALPix is a way to *index* equal-area regions on the unit sphere using integers.\n",
    "\n",
    "To decode HEALPix indices, you need to know the resolution of the map, which is described by a parameter called `nside`. `nside` is the number of subdivisions of 12 base HEALPix tiles, so the relation between the length of a HEALPix array, `npix`, and its resolution, `nside`, is\n",
    "\n",
    "$$\n",
    "    \\mathsf{npix} = 12 \\cdot \\mathsf{nside}^2.\n",
    "$$\n",
    "\n",
    "The functions `hp.npix2nside` and `hp.nside2npix` convert between length and resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npix = len(prob)\n",
    "npix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = hp.npix2nside(npix)\n",
    "nside"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `hp.pix2ang` allow us to convert from (ra, dec) and HEALPix pixel index.\n",
    "\n",
    "*Note*: by default, these functions return 'physics' spherical coordinates $(\\theta, \\phi)$ in radians, but you can switch to 'astronomy' spherical coordinates in degrees by passing the keyword argument `lonlat=True`.\n",
    "\n",
    "Let's look up the right asce3nsion and declination of pixel 123."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipix = 123\n",
    "ra, dec = hp.pix2ang(nside, ipix, lonlat=True)\n",
    "ra, dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `hp.ang2pix` does the opposite. Let's find the pixel that contains the point RA=194.95, Dec=27.98."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = 194.95\n",
    "dec = 27.98\n",
    "hp.ang2pix(nside, ra, dec, lonlat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the most probable sky location? Just find the pixel with the maximum valuem, and then find its right ascension and declination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipix_max = np.argmax(prob)\n",
    "ipix_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.pix2ang(nside, ipix_max, lonlat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability distributions with scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy provides a \"t\" distribution class that we can use to get values from the \"t\" statistic probability density function (PDF). As a start, we plot the PDF for a \"t\" statistic with 3 degrees of freedom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dist = scipy.stats.t(3)\n",
    "t_values = np.linspace(-4, 4, 1000)\n",
    "plt.plot(t_values, t_dist.pdf(t_values))\n",
    "plt.xlabel('t value')\n",
    "plt.ylabel('probability for t value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t distribution object t_dist can also give us the cumulative distribution function (CDF). The CDF gives the area under the curve of the PDF at and to the left of the given t value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_values, t_dist.cdf(t_values))\n",
    "plt.xlabel('t value')\n",
    "plt.ylabel('probability for t value <= t')\n",
    "plt.title('CDF for t distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say I have a t value x drawn from a t distribution. The PDF gives the probability for given values of x. Because it is a probability density, the sum of the probabilities of all possible values for x: ∞<x<∞ must be 1. Therefore the total area under the PDF curve is 1, and the maximum value of the CDF is 1.\n",
    "\n",
    "The CDF gives us the area under the PDF curve at and to the left of a given t value x. Therefore it is the probability that we will observe a value x<=t if we sample a value x from a t distribution.\n",
    "\n",
    "Let's show relationship of PDF and CDF for three example t values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_values = (-1.5, 0, 1.5)\n",
    "pdf_values = t_dist.pdf(t_values)\n",
    "cdf_values = t_dist.cdf(t_values)\n",
    "fill_color = (0, 0, 0, 0.1)  # Light gray in RGBA format.\n",
    "line_color = (0, 0, 0, 0.5)  # Medium gray in RGBA format.\n",
    "fig, axes = plt.subplots(2, len(example_values), figsize=(10, 6))\n",
    "for i, x in enumerate(example_values):\n",
    "    cdf_ax, pdf_ax = axes[:, i]\n",
    "    cdf_ax.plot(t_values, cdf_values)\n",
    "    pdf_ax.plot(t_values, pdf_values)\n",
    "    # Fill area at and to the left of x.\n",
    "    pdf_ax.fill_between(t_values, pdf_values,\n",
    "                        where=t_values <= x,\n",
    "                        color=fill_color)\n",
    "    pd = t_dist.pdf(x)  # Probability density at this value.\n",
    "    # Line showing position of x on x-axis of PDF plot.\n",
    "    pdf_ax.plot([x, x],\n",
    "                [0, pd], color=line_color)\n",
    "    cd = t_dist.cdf(x)  # Cumulative distribution value for this x.\n",
    "    # Lines showing x and CDF value on CDF plot.\n",
    "    x_ax_min = cdf_ax.axis()[0]  # x position of y axis on plot.\n",
    "    cdf_ax.plot([x, x, x_ax_min],\n",
    "                [0, cd, cd], color=line_color)\n",
    "    cdf_ax.set_title('x = {:.1f}, area = {:.2f}'.format(x, cd))\n",
    "    # Hide top and right axis lines and ticks to reduce clutter.\n",
    "    for ax in (cdf_ax, pdf_ax):\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, say I have drawn a t value x at random from a t distribution. The probability that x<=1.5 is (i.e., >0.9253):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dist.cdf(1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total area under the PDF is 1, and the maximum value for the CDF is 1. Therefore the area of the PDF to the right of 1.5 must be (i.e., >0.0746):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - t_dist.cdf(1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the probability that our t value x will be >1.5. In general, when we sample a value x at random from a t distribution, the probability that x>q is given by:\n",
    "\n",
    "ℙ(x>q)=1−CDF(q), where CDF is the cumulative distribution function for a t value. We can apply the same methodology to HEALpix pixel probabilities in LIGO/VIRGO localization maps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with LIGO/Virgo 3D localizations and Cross-Matching to Galaxy Catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get our galaxy catalog that we will later match to the 3D localization of GW170817.\n",
    "\n",
    "For this Section we will use a galaxy catalog from the CLU project (Census of the Local Universe; paper: https://ui.adsabs.harvard.edu/abs/2017arXiv171005016C/abstract). However, we will only use those galaxies that are publically availble and in NED (NASA/IPAC Extragalactic Database: https://ned.ipac.caltech.edu/). This catalog has already been prepared for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load CLU catalog into astropy table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu=Table.read('data/CLU_NEDonly.fits')\n",
    "nclu=np.size(clu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add probability columns to the galaxy catalog: probability density and p-value per volume and per area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probdencol=Column(np.zeros(nclu,dtype='f4'),name='dP_dV')\n",
    "probcol=Column(np.zeros(nclu,dtype='f4'),name='P')\n",
    "probdenAcol=Column(np.zeros(nclu,dtype='f4'),name='dP_dA')\n",
    "probAcol=Column(np.zeros(nclu,dtype='f4'),name='P_A')\n",
    "clu.add_columns([probdencol,probcol,probdenAcol,probAcol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Familiarize yourself with the catalog\n",
    "\n",
    "print the columns in the catalog that will be used in the cross-match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu['NEDname','RA','DEC','TYPE_NED','DISTMPC','Z','ZERR','MODELMAG_R','K_M_K20FE','K_MSIG_K20FE','W1MPRO','W1SIGMPRO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'RA'=Right Ascension in degrees  <br>\n",
    "'Dec'=Declination in degrees  <br>\n",
    "'MODELMAG_R'=SDSS r-band magnitude  <br>\n",
    "'MODELMAGERR_R'=SDSS r-band magnitude Error  <br>\n",
    "'K_M_K20FE'=2MASS K-band magnitude  <br>\n",
    "'K_MSIG_K20FE'=2MASS K-band magnitude Error  <br>\n",
    "'W1MPRO'=WISE W1 magnitude (3.6 micron)  <br>\n",
    "'W1SIGMPRO'=WISE W1 magnitude Error  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Excercise\n",
    "Use the astropy.coordinates package and the SkyCoord function to store all of the galaxy catalog's locations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The astropy coordinates package provides classes for representing a variety of celestial/spatial coordinates and their velocity components, as well as tools for converting between common coordinate systems in a uniform way. In addition, the astropy coordinates package facilitates fast manipulation and cross-matching. See here for examples: https://docs.astropy.org/en/stable/coordinates/\n",
    "\n",
    "Create a coordinate object for the entire CLU catalog (hint: use SkyCoord)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clucoord="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GW170817 3D Localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read in the LIGO/VIRGO HEALpix map for GW170817.\n",
    "\n",
    "LIGO/Virgo localization files for compact binary mergers include directional estimates of distance. The distance information is stored in three additional columns. To get the distance estimates, we need to ask for all four columns: `PROB`, `DISTMU`, `DISTSIGMA`, and `DISTNORM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://dcc.ligo.org/public/0146/G1701985/001/preliminary-LALInference.fits.gz'\n",
    "filename = astropy.utils.data.download_file(url)\n",
    "\n",
    "prob, distmu, distsigma, distnorm = hp.read_map(filename, field=[0, 1, 2, 3])\n",
    "\n",
    "npix = len(prob)\n",
    "nside = hp.npix2nside(npix)\n",
    "pixarea = hp.nside2pixarea(nside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Excercise\n",
    "\n",
    "Find the coordinates of the highest probability pixel and put the coordinates into an astropy coordinate object called 'center'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipix_max = \n",
    "ra_max, dec_max = \n",
    "center = \n",
    "print('Coordinates (RA,Dec) = %s' %(center))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other plotting packages for LIGO/VIRGO HEALPix maps.\n",
    "\n",
    "There are many visualization packages for plotting HEALPix maps. Luckily, LIGO has taken the time to provide its own user-friendly wrapper for plotting LIGO/VIRGO localizations.\n",
    "\n",
    "Let's plot the sky localization using an 'astroglobe' projection centered on the highest highest probability pixel and overplot this location using the ligo.skymap package. (see here: https://lscsoft.docs.ligo.org/ligo.skymap/ligo/skymap/plot/allsky.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(\n",
    "    [0.05, 0.05, 0.9, 0.9],\n",
    "    projection='astro globe',\n",
    "    center=center)\n",
    "\n",
    "ax.grid()\n",
    "ax.imshow_hpx(filename, cmap='cylon')\n",
    "ax.plot(\n",
    "    center.ra.deg, center.dec.deg,\n",
    "    transform=ax.get_transform('world'),\n",
    "    marker=ligo.skymap.plot.reticle(inner=0,outer=1),\n",
    "    markersize=10,\n",
    "    markeredgewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Excercises\n",
    "1. Back to the galaxy catalog. Calculate the HEALPix index for each galaxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipix="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compute the probabilities of each galaxy: per area, per radial distance, and per volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability density per area on the sky for each galaxy\n",
    "dp_dA=\n",
    "clu['dP_dA']=dp_dA\n",
    "\n",
    "#probability along radial distance\n",
    "dp_dr=clu['DISTMPC']**2 * distnorm[ipix] * norm(distmu[ipix],distsigma[ipix]).pdf(clu['DISTMPC'])\n",
    "\n",
    "#probability density per volume\n",
    "dp_dV=\n",
    "clu['dP_dV']=dp_dV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use a normalized cumulative dist function to calculate P-value per area for each galaxy (hint: use np.cumsum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu.sort('dP_dA')\n",
    "cumnorm_sort=\n",
    "clu['P_A']=cumnorm_sort\n",
    "\n",
    "#ID galaxies inside the 90% prob by volume\n",
    "icutarea90=\n",
    "clucutarea90=\n",
    "\n",
    "#generate astropy coordinate object for this sample\n",
    "clucutarea90coord=\n",
    "\n",
    "print('# of galaxies in 90%% Area = %i' %(np.size(icutarea90)))\n",
    "\n",
    "#sort the galaxies by P-value and print out top 20\n",
    "clucutarea90['NEDname','dP_dA','P_A'][0:20].pprint(max_lines=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the top 20 highest probability galaxies and add a zoomed-in inset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(\n",
    "    [0.05, 0.05, 0.9, 0.9],\n",
    "    projection='astro globe',\n",
    "    center=center)\n",
    "\n",
    "#Zoomed-in inset window to better view the locations of the galaxies.\n",
    "ax_inset = plt.axes(\n",
    "    [0.59, 0.3, 0.4, 0.4],\n",
    "    projection='astro zoom',\n",
    "    center=center,\n",
    "    radius=15*u.deg)\n",
    "for key in ['ra', 'dec']:\n",
    "    ax_inset.coords[key].set_ticklabel_visible(False)\n",
    "    ax_inset.coords[key].set_ticks_visible(False)\n",
    "ax.grid()\n",
    "ax.mark_inset_axes(ax_inset)\n",
    "ax.connect_inset_axes(ax_inset, 'upper left')\n",
    "ax.connect_inset_axes(ax_inset, 'lower left')\n",
    "ax_inset.scalebar((0.1, 0.1), 5 * u.deg).label()\n",
    "ax_inset.compass(0.9, 0.1, 0.2)\n",
    "\n",
    "ax.imshow_hpx('data/GW170817_prelim.fits.gz', cmap='cylon')\n",
    "ax_inset.imshow_hpx('data/GW170817_prelim.fits.gz', cmap='cylon')\n",
    "\n",
    "for coord in clucutarea90coord:\n",
    "    ax_inset.plot(\n",
    "    coord.ra.deg, coord.dec.deg,\n",
    "    transform=ax_inset.get_transform('world'),\n",
    "    marker=ligo.skymap.plot.reticle(inner=0,outer=1),\n",
    "    markersize=10,\n",
    "    markeredgewidth=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise for students - Put it all Together...\n",
    "\n",
    "Following the examples above, find galaxies in 90% __VOLUME__ probability contour for GW170817, sort by Wise W1 luminosity, and overplot the top 20 sorted galaxies.\n",
    "\n",
    "Information on WISE zeropoints and flux transformations\n",
    "http://wise2.ipac.caltech.edu/docs/release/allsky/expsup/sec4_4h.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I - Find the galaxies in the 90% volumne probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in CLU catalog\n",
    "clu= \n",
    "\n",
    "#make astropy coordinate object of CLU galaxies\n",
    "clucoord=\n",
    "\n",
    "#sky localization colmns to the galaxy catalog: probability density and p-value per volume and per area.\n",
    "probdencol=Column(np.zeros(nclu,dtype='f4'),name='dP_dV')\n",
    "probcol=Column(np.zeros(nclu,dtype='f4'),name='P')\n",
    "probdenAcol=Column(np.zeros(nclu,dtype='f4'),name='dP_dA')\n",
    "probAcol=Column(np.zeros(nclu,dtype='f4'),name='P_A')\n",
    "clu.add_columns([probdencol,probcol,probdenAcol,probAcol])\n",
    "\n",
    "#load in healpix map and calculate npix, nside, and pixarea\n",
    "\n",
    "#get coord of max prob density for plotting purposes and call it 'centr'\n",
    "center = \n",
    "\n",
    "#calc hp index for each galaxy and populate CLU Table with the values\n",
    "ipix=\n",
    "\n",
    "#calc probability density per volume for each galaxy\n",
    "dp_dV=\n",
    "clu['dP_dV']=dp_dV\n",
    "\n",
    "#use normalized cumulative dist function to calculate Volume P-value for each galaxy\n",
    "cumnorm_sort=\n",
    "clu['P']=cumnorm_sort\n",
    "\n",
    "#ID galaxies inside the 90% prob by volume\n",
    "icut90=\n",
    "clucut90=clu[icut90]\n",
    "\n",
    "#generate an astropy coordinate object for this subset\n",
    "clucut90coord=\n",
    "\n",
    "print('# of galaxies in 90%% volume = %i' %(np.size(clucut90)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Why are there so fewer galaxies in the volumne probability?<br>\n",
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part II - Sort by WISE W1 Luminosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a WISE W1 luminosity column to the CLU table\n",
    "W1lumcol=Column(np.zeros(nclu,dtype='f8'),name='LumW1')\n",
    "clu.add_column(W1lumcol)\n",
    "\n",
    "#constansts needed\n",
    "F0=309.540\n",
    "clight=2.99792458e18   #Angstoms/sec\n",
    "lamW1=33526.   #Angtroms\n",
    "\n",
    "fluxJyW1=F0*10**(-0.4*clucut90['W1MPRO'])  #in Jy\n",
    "fluxdenW1=  #erg/s/cm^2/Hz\n",
    "freqW1=\n",
    "\n",
    "clucut90['LumW1']=\n",
    "\n",
    "#sort by WISE 1 Luminosity (proportional to galaxy stellar mass)\n",
    "\n",
    "#then print list of prioritized galaxies\n",
    "clucut90['NEDname','LumW1','dP_dV','P'][0:20].pprint(max_lines=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Is NGC4993 in your list?<br>\n",
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III - Plot up the sky localization and overplot the top 20 sorted galaxies on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot up the sky localization and overplot the galaxies\n",
    "\n",
    "#where is NGC4993? hint: use ax_inset.text()\n",
    "c4993=SkyCoord.from_name('NGC 4993')\n",
    "ax_inset.text()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
